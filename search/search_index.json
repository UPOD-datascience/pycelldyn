{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the documentation of","text":"<p>A Python package for working with CELL-DYN (i.e., Sapphire and Alinity hq) data. </p>"},{"location":"setup/","title":"Setup","text":""},{"location":"setup/#installation","title":"Installation","text":"<ol> <li> <p>Create a new environment using either <code>conda</code> (recommended) or <code>venv</code> and activate it</p> </li> <li> <p>Use UPOD's Cookiecutter for Data Science Projects and generate a new project template.</p> </li> <li> <p>Install the <code>PyCellDyn</code> package using <code>pip</code> with the following command:</p> </li> </ol> <pre><code>pip install git+https://github.com/UPOD-datascience/pycelldyn\n</code></pre> <p>3.1 <code>pip</code> will try to install the required dependencies. However, for some reason sometimes the SSL certificate can't be confirmed and the installation throws an error:</p> <pre><code>Could not fetch URL https://pypi.python.org/simple/PACKAGENAME/: There was a problem confirming the ssl certificate: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777) - skipping\nCould not find a version that satisfies the requirement PACKAGENAME (from versions: XXX)\n</code></pre> <p>In that case, you need to install the missing packages one by one by hand with the following command:</p> <pre><code>pip install PACKAGENAME --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org\n</code></pre> <p>That's it! You are done.</p>"},{"location":"api_reference/miscellaneous/","title":"Miscellaneous","text":"<p>These functions provide handy tools that can be used in different places and do not belong to a specific module.</p> <p><code>get_flag_names</code></p> <p>Parameters:</p> Name Type Description Default <code>cols_values</code> <code>list</code> <p>Each element is a</p> required <p>Returns:</p> Name Type Description <code>flag_names</code> <code>list</code> <p>Each element is the flag column name corresponding to an element of <code>cols_values</code>.</p> Source code in <code>pycelldyn/miscellaneous.py</code> <pre><code>def get_flag_names(cols_values):\n    \"\"\" `get_flag_names`\n\n    Parameters\n    ----------\n    cols_values : list\n        Each element is a\n\n    Returns\n    -------\n    flag_names : list\n        Each element is the flag column name corresponding to an element\n        of `cols_values`.\n    \"\"\"\n\n    flag_names = []\n    for col in cols_values:\n\n        # First, let's look at the special cases (i.e., exceptions)\n        if (col == 'hb_nl') or (col == 'hb_usa'):\n            flag_name = 'hb_flag'\n        elif (col == 'mch_nl') or (col == 'mch_usa'):\n            flag_name = 'mch_flag'\n        elif (col == 'mchc_nl') or (col == 'mchc_usa'):\n            flag_name = 'mchc_flag'\n        elif (col == 'mchr_nl') or (col == 'mchr_usa'):\n            flag_name = 'mchr_flag'\n        elif (col == '') or (col == ''):\n            flag_name = ''\n\n        # Otherwise, we can just append `_flag` at the end.\n        else:\n            flag_name = col + '_flag'\n\n        flag_names.append(flag_name)\n\n    return flag_names\n</code></pre> <p><code>get_cols_wbc_scatter</code></p> <p>Get a list of column names that correspond to scatter measurement of white blood cells (WBCs).</p> <p>Warning</p> <p>Not to be confused with columns corresponding to WBC counts or sizes.</p> <p>Tip</p> <p>In order to get the coefficient of variance (CV) columns, just append <code>_cv</code> to each element of <code>cols_wbc_measurements</code>. For example:</p> <p><code>cols_cv = [c + '_cv' for c in get_cols_wbc_measurements()]</code></p> <p>Parameters:</p> Name Type Description Default <code>None</code> required <p>Returns:</p> Name Type Description <code>cols_wbc_measurements</code> <code>list</code> <p>List of column names that correspond to scatter measurements of WBCs.</p> Source code in <code>pycelldyn/miscellaneous.py</code> <pre><code>def get_cols_wbc_scatter():\n    \"\"\" `get_cols_wbc_scatter`\n\n    Get a list of column names that correspond to scatter measurement of\n    white blood cells (WBCs).\n\n    !!! warning\n        Not to be confused with columns corresponding to WBC counts or sizes.\n\n    !!! tip\n        In order to get the coefficient of variance (CV) columns, just\n        append `_cv` to each element of `cols_wbc_measurements`. For\n        example:\n\n        `cols_cv = [c + '_cv' for c in get_cols_wbc_measurements()]`\n\n    Parameters\n    ----------\n    None\n\n    Returns\n    -------\n    cols_wbc_measurements : list\n        List of column names that correspond to scatter measurements of WBCs.\n    \"\"\"\n    # TODO: Should we keep this function at all or should this be relegated\n    # to the QC functions exclusively?\n\n    cols_wbc_scatter = ['neutrophil_size_mean',\n                        'neutrophil_intracellular_complexity',\n                        'neutrophil_lobularity_polarized',\n                        'neutrophil_lobularity_depolarized',\n                        'neutrophil_dna_staining',\n                        'lymphocyte_size_mean',\n                        'lymphocyte_intracellular_complexity'\n                        ]\n\n    return cols_wbc_scatter\n</code></pre> <p><code>get_cols_with_values</code></p> <p>Get a list of column names that correspond to actual parameter values (i.e., not flags nor alerts)</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>Original DataFrame</p> required <p>Returns:</p> Name Type Description <code>cols_with_values</code> <code>list</code> <p>Columns with values based on their corresponding _flag counterparts.</p> Source code in <code>pycelldyn/miscellaneous.py</code> <pre><code>def get_cols_with_values(df):\n    \"\"\" `get_cols_with_values`\n\n    Get a list of column names that correspond to actual parameter values\n    (i.e., not flags nor alerts)\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        Original DataFrame\n\n    Returns\n    -------\n    cols_with_values : list\n        Columns with values based on their corresponding _flag counterparts.\n\n    \"\"\"\n    # Get columns from the original DataFrame with _flag suffix.\n    cols_flags = get_elements_with_substring(df.columns, ['_flag'])\n\n    # Obtain the original parameter name by removing the suffix.\n    cols_with_values = [col_with_value.replace('_flag', '') for col_with_value in cols_flags ]\n\n\n    # TODO\n    # Correct for flags to correspond to two variables\n    # e.g., hb_flag apply to both hb_usa and hb_nl\n\n    return cols_with_values\n</code></pre> <p><code>get_elements_with_substring</code></p> <p>Get elements of a list that have a specific substring.</p> <p>Tip</p> <p>This is a handy function to get flag columns (e.g., columns which name end with <code>_flag</code> or that start with <code>flag_</code>).</p> <p>Parameters:</p> Name Type Description Default <code>base_list</code> <code>list</code> <p>Base lists (for example, <code>list(df.columns)</code>)</p> required <code>substr_list</code> <code>list</code> <p>Each element of the list is a substring to be found.</p> <p>Tip</p> <p>If interested in only one substring, pass a list with one element.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List with the elements that have the given substring. If none, returns an empty list.</p> References <ul> <li>Filtering a list of strings based on a substring</li> </ul> Source code in <code>pycelldyn/miscellaneous.py</code> <pre><code>def get_elements_with_substring(base_list, substr_list):\n    \"\"\" `get_elements_with_substring`\n\n    Get elements of a list that have a specific substring.\n\n    !!! tip\n        This is a handy function to get flag columns (e.g., columns which\n        name end with `_flag` or that start with `flag_`).\n\n    Parameters\n    ----------\n    base_list : list\n        Base lists (for example, `list(df.columns)`)\n\n    substr_list : list\n        Each element of the list is a substring to be found.\n\n        !!! tip\n            If interested in only one substring, pass a list with one element.\n\n    Returns\n    -------\n    list\n        List with the elements that have the given substring.\n        If none, returns an empty list.\n\n    References\n    ----------\n    * [Filtering a list of strings based on a substring](https://www.geeksforgeeks.org/python-filter-list-of-strings-based-on-the-substring-list/)\n    \"\"\"\n\n    return [str for str in base_list if\n             any(sub in str for sub in substr_list)]\n</code></pre>"},{"location":"api_reference/preprocessing/","title":"Pre-processing","text":"<p>These functions perform pre-processing steps on the raw data.</p> <p><code>rename_columns</code></p> <p>Rename the columns so that they have computer names as defined in the given data dictionary.</p> <p>Tip</p> <p>Renaming the columns should always be the first pre-processing step.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>The pandas DataFrame.</p> required <code>df_data_dictionary</code> <code>pandas DataFrame</code> <p>DataFrame with data dictionary information. It should have at least the following columns:</p> <ul> <li><code>Name</code> - The original name of the column in the raw data</li> <li><code>Computer name</code> - The computer name defined in the dictionary</li> </ul> required <code>verbose</code> <code>bool</code> <p>Define if verbose output will be printed (<code>True</code>) or not (<code>False</code>).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>df_renamed</code> <code>pandas DataFrame</code> <p>Same as input <code>df</code>, but with the columns renamed according to the data dictionary mapping.</p> Source code in <code>pycelldyn/preprocessing.py</code> <pre><code>def rename_columns(df, df_data_dictionary, verbose=True):\n    \"\"\"`rename_columns`\n\n    Rename the columns so that they have computer names as defined\n    in the given data dictionary.\n\n    !!! tip\n        Renaming the columns should always be the first pre-processing step.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        The pandas DataFrame.\n\n    df_data_dictionary : pandas DataFrame\n        DataFrame with data dictionary information. It should have\n        at least the following columns:\n\n        * `Name` - The original name of the column in the raw data\n        * `Computer name` - The computer name defined in the dictionary\n\n    verbose : bool\n        Define if verbose output will be printed (`True`) or not (`False`).\n\n    Returns\n    -------\n    df_renamed : pandas DataFrame\n        Same as input `df`, but with the columns renamed according\n        to the data dictionary mapping.\n    \"\"\"\n    if verbose:\n        print(\"Renaming columns...\", flush=True, end='')\n\n    # Check that columns of interest are present in the data dictionary.\n    for col in ['Name', 'Computer name']:\n        if col not in df_data_dictionary.columns:\n            raise Exception(f\"Column '{col}' not present in df_data_dictionary\")\n\n    # Select the data dictionary's columns of interest.\n    df_data_dictionary = df_data_dictionary[['Name', 'Computer name']]\n\n    # Convert DataFrame to dictionary.\n    df_data_dictionary_dict = dict(zip(df_data_dictionary['Name'].values,\n                                       df_data_dictionary['Computer name'].values))\n\n    # Perform the renaming.\n    df_renamed = df.rename(columns=df_data_dictionary_dict)\n\n    if verbose:\n        print(\"\\tDONE!\")\n\n\n    return df_renamed\n</code></pre> <p><code>clean_dataframe</code></p> <p>Clean categorical and numerical columns of a Sapphire or Alinity DataFrame.</p> <p>Info</p> <p>To identify what type a column is, this function uses information from the given data dictionary:</p> <ul> <li>Numerical columns are those that have a <code>Type</code> of <code>int</code>, <code>float</code>, or <code>int (scientific notation)</code>.</li> <li>Categorical columns are those that have a <code>Type</code> of <code>str</code>.</li> <li>Columns that fall outside of these types remain unchanged.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>The pandas DataFrame.</p> required <code>df_data_dictionary</code> <code>pandas DataFrame</code> <p>DataFrame with data dictionary information. It should have at least the following columns:</p> <ul> <li><code>Computer name</code> - The computer name of each parameter.</li> <li><code>Type</code> - Variable type</li> </ul> required <code>cols</code> <code>list of str</code> <p>List with the columns to be cleaned. If <code>None</code>, all columns will be (attempted to be) cleaned.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Define if verbose output will be printed (<code>True</code>) or not (<code>False</code>).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>df_clean</code> <code>pandas DataFrame</code> <p>Clean DataFrame.</p> Source code in <code>pycelldyn/preprocessing.py</code> <pre><code>def clean_dataframe(df, df_data_dictionary, cols=None, verbose=True):\n    \"\"\"`clean_dataframe`\n\n    Clean categorical and numerical columns of a Sapphire or Alinity\n    DataFrame.\n\n    !!! info\n        To identify what type a column is, this function uses information\n        from the given data dictionary:\n\n        * Numerical columns are those that have a `Type` of `int`,\n        `float`, or `int (scientific notation)`.\n        * Categorical columns are those that have a `Type` of `str`.\n        * Columns that fall outside of these types remain unchanged.\n\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        The pandas DataFrame.\n\n    df_data_dictionary : pandas DataFrame\n        DataFrame with data dictionary information. It should have\n        at least the following columns:\n\n        * `Computer name` - The computer name of each parameter.\n        * `Type` - Variable type\n\n    cols : list of str\n        List with the columns to be cleaned. If `None`,\n        all columns will be (attempted to be) cleaned.\n\n    verbose : bool\n        Define if verbose output will be printed (`True`) or not (`False`).\n\n    Returns\n    -------\n    df_clean : pandas DataFrame\n        Clean DataFrame.\n    \"\"\"\n\n    if verbose:\n        print(\"Cleaning columns...\")\n\n    # Check that columns of interest are present in the data dictionary.\n    for col in ['Computer name', 'Type']:\n        if col not in df_data_dictionary.columns:\n            raise Exception(f\"Column '{col}' not present in df_data_dictionary\")\n\n    # Select the data dictionary's columns of interest.\n    df_data_dictionary = df_data_dictionary[['Computer name', 'Type']]\n    df_data_dictionary = df_data_dictionary.set_index('Computer name')\n\n\n    # Define which columns will be cleaned.\n    if cols is None:\n        cols = df.columns\n\n    # Perform cleaning of columns.\n    # This is done one by one and depending on the column type.\n    types_numerical = ['int', 'float', 'int (scientific notation)']\n    types_categorical = ['str', 'string']\n\n    df_clean = df.copy()\n    for col in cols:\n        # In case we ever will need to use unit information, we can\n        # do so by uncommenting this line:\n        # col_unit = str(df_dictionary.loc[col, 'Unit']).lower()\n\n        # If a column name starts with an underscore (_), it means that\n        # it is meant to be ignored (for example, in cases when columns\n        # are duplicated.\n        if col[0] == '_':\n            if verbose:\n                print(f\"- Column {col} is to be ignored.\")\n            continue\n\n        col_type = str(df_data_dictionary.loc[col, 'Type']).lower()\n\n        if col_type in types_numerical:\n            if verbose:\n                print(f\"+ Cleaning numerical ({col_type}) column {col}...\", end='', flush=True)\n            df_clean[col] = clean_column_numerical(df, col)\n\n            if verbose:\n                print(\"\\t DONE!\")\n\n        elif col_type in types_categorical:\n            if verbose:\n                print(f\"+ Cleaning categorical ({col_type}) column {col}...\", end='', flush=True)\n            df_clean[col] = clean_column_categorical(df, col)\n            if verbose:\n                print(\"\\t DONE!\")\n        else:\n            if verbose:\n                print(f\". Column {col} will not be cleaned and left as is.\")\n\n\n    if verbose:\n        print(\"\\tDONE!\")\n\n\n    return df_clean\n</code></pre> <p><code>clean_column_numerical</code></p> <p>Clean a numerical column. It applies the following steps:</p> <ul> <li>Convert empty spaces (i.e., <code>' '</code>) to <code>NaN</code>s.</li> <li>Convert weird entries with a value of <code>\\xa0</code> to <code>NaN</code>s.</li> <li>Convert entries with a value of <code>'nan'</code> to <code>NaN</code>s.</li> <li>Cast to float to ensure that values will be numbers.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>The pandas DataFrame.s</p> required <code>col</code> <code>string</code> <p>Name of the numerical column to be cleaned.</p> required <p>Returns:</p> Name Type Description <code>col_clean</code> <code>pandas Series</code> <p>The clean (numerical) column.</p> Source code in <code>pycelldyn/preprocessing.py</code> <pre><code>def clean_column_numerical(df, col):\n    \"\"\"`clean_column_numerical`\n\n    Clean a numerical column. It applies the following steps:\n\n    * Convert empty spaces (i.e., `' '`) to `NaN`s.\n    * Convert weird entries with a value of `\\\\xa0` to `NaN`s.\n    * Convert entries with a value of `'nan'` to `NaN`s.\n    * Cast to float to ensure that values will be numbers.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        The pandas DataFrame.s\n\n    col : string\n        Name of the numerical column to be cleaned.\n\n    Returns\n    -------\n    col_clean: pandas Series\n        The clean (numerical) column.\n    \"\"\"\n    df_clean = df.copy(deep=True)\n\n    # Clean weird string entries.\n    df_clean.loc[df[col]==' ', col] = np.nan\n    df_clean.loc[df[col]=='\\xa0', col] = np.nan\n    df_clean.loc[df[col]=='nan', col] = np.nan\n\n    # Cast to float (i.e., ensure that it will be a number).\n    df_clean[col] = df_clean[col].astype(float)\n\n    return df_clean[col]\n</code></pre> <p><code>clean_column_categorical</code></p> <p>Clean a categorical column. It applies the following steps:</p> <ul> <li>Make strings lower case</li> <li>Remove leading spaces</li> <li>Remove trailing spaces</li> <li>Convert weird entries with a value of <code>\\xa0</code> to <code>NaN</code>s.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>The pandas DataFrame.</p> required <code>col</code> <code>str</code> <p>Name of the categorical column to be cleaned.</p> required <p>Returns:</p> Name Type Description <code>col_clean</code> <code>pandas Series</code> <p>The clean (categorical) column.</p> Source code in <code>pycelldyn/preprocessing.py</code> <pre><code>def clean_column_categorical(df, col):\n    \"\"\"`clean_column_categorical`\n\n    Clean a categorical column. It applies the following steps:\n\n    * Make strings lower case\n    * Remove leading spaces\n    * Remove trailing spaces\n    * Convert weird entries with a value of `\\\\xa0` to `NaN`s.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        The pandas DataFrame.\n\n    col : str\n        Name of the categorical column to be cleaned.\n\n    Returns\n    -------\n    col_clean: pandas Series\n        The clean (categorical) column.\n    \"\"\"\n\n    df_clean = df.copy(deep=True)\n\n    # Make lower case, remove leading/trailing spaces, and convert\n    # apostrophes to proper format (\u2019 --&gt; ').\n    def _clean_string(string):\n\n        if isinstance(string, str):\n            clean_string = string.lower().strip()\n            clean_string = clean_string.replace(\"\u2019\", \"'\")\n\n        else:\n            clean_string = string\n\n        return clean_string\n    df_clean[col] = df_clean[col].apply(_clean_string)\n\n    # Remove weird string entries.\n    df_clean.loc[df[col]=='\\xa0', col] = np.nan\n\n    return df_clean[col]\n</code></pre>"},{"location":"api_reference/quality_control/","title":"Quality control","text":"<p>These functions perform quality control checks on the clean data.</p> <p>Warning</p> <p>There is no golden standard for performing quality control checks!</p> <p>Be careful when choosing which checks to apply, since they can have very different effects in your data. This could potentially result in, for example, inappropriate patient selection or bias.</p> <p>Please make sure you consult with an UPOD expert.</p> <p><code>perform_qc</code></p> <p>Perform quality control (QC) on the data of the given DataFrame. For more information, see each of the <code>qc_types</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>DataFrame with the clean data to be checked.</p> <p>Tip</p> <p>Cleaning can be done using the function <code>clean_dataframe</code></p> required <code>qc_types</code> <code> list of str</code> <p>List of quality control types. Possible values for each element are:</p> QC type Description Additional comments <code>wbc_scatter</code> or <code>leuko_scatter</code> QC of parameters regarding the scatter measurement of white blood cells Not to be confused with WBC counts or sizes <code>rbc</code> or <code>erythro</code> QC of (some) red blood cell parameters. Not all RBC parameters get QC! <code>plausible_range</code> QC of plausible ranges of different parameters Min and max values are defined in the corresponding data dictionary <code>flags</code> or <code>suspicious_flags</code> QC based on the presence of suspicious values (defined by corresponding flags) <code>fail</code> or <code>failure</code> Set parameter values to <code>NaN</code> based on corresponding flags) <code>standard_values</code> Set standard values to a given set of parameters Not recommended! <code>all</code> All of the previous QC <code>['wbc_scatter', 'rbc_scatter', 'plausible_range', 'flags']</code> <code>machine</code> <code>str</code> <p>What machine does the data correspond to. Possible values are:</p> <ul> <li><code>sapphire</code> or <code>sapph</code> - Sapphire</li> <li><code>alinity</code> or <code>alin</code> - Alinity hq</li> </ul> <p>Info</p> <p>No functionality yet, but might be useful in the future.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Define if verbose output will be printed (<code>True</code>) or not (<code>False</code>).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>df_qc</code> <code>pandas DataFrame</code> <p>DataFrame with quality controlled data.</p> Source code in <code>pycelldyn/quality_control.py</code> <pre><code>def perform_qc(df, qc_types=['wbc_scatter', 'rbc_scatter', 'plausible_range', 'flags'], machine=None, verbose=True):\n    \"\"\" `perform_qc`\n\n    Perform quality control (QC) on the data of the given DataFrame.\n    For more information, see each of the `qc_types`.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        DataFrame with the clean data to be checked.\n\n        !!! tip\n            Cleaning can be done using the function `clean_dataframe`\n\n    qc_types :  list of str\n        List of quality control types. Possible values for each element are:\n\n        | QC type                            | Description                                                     | Additional comments                                               |\n        |------------------------------------|-----------------------------------------------------------------|-------------------------------------------------------------------|\n        | `wbc_scatter` or `leuko_scatter`   | QC of parameters regarding the scatter measurement of white blood cells | Not to be confused with WBC counts or sizes               |\n        | `rbc` or `erythro`                 | QC of (some) red blood cell parameters.                         | Not all RBC parameters get QC!                                    |\n        | `plausible_range`                  | QC of plausible ranges of different parameters                  | Min and max values are defined in the corresponding data dictionary |\n        | `flags` or `suspicious_flags`      | QC based on the presence of suspicious values (defined by corresponding flags) |                                                    |\n        | `fail` or `failure`                | Set parameter values to `NaN` based on corresponding flags)     |                                                                   |\n        | `standard_values`                  | Set standard values to a given set of parameters                | Not recommended!                                                  |\n        | `all`                              | All of the previous QC                                          |                                                                   |\n\n    machine : str\n        What machine does the data correspond to. Possible values are:\n\n        * `sapphire` or `sapph` - Sapphire\n        * `alinity` or `alin` - Alinity hq\n\n        !!! info\n            No functionality yet, but might be useful in the future.\n\n    verbose : bool\n        Define if verbose output will be printed (`True`) or not (`False`).\n\n    Returns\n    -------\n    df_qc : pandas DataFrame\n        DataFrame with quality controlled data.\n    \"\"\"\n    df_qc = df.copy()\n\n    # Check that qc_types is not empty\n    if qc_types == []:\n        raise(\"qc_types is empty.\")\n\n    # Check if `all` QCs are needed.\n    qc_types_possible = ['wbc_scatter', 'rbc_scatter', 'plausible_range', 'flags', 'fail', 'standard_values']\n    if (qc_types == 'all') or ('all' in qc_types):\n        qc_types = qc_types_possible\n\n\n    # Perform each of the QC types.\n    for qc in qc_types:\n\n        if qc in qc_types_possible:\n\n            if verbose:\n                print(f\"Performing QC {qc}...\", end=\"\", flush=True)\n\n            match qc:\n\n                case 'wbc_scatter' | 'leuko_scatter':\n                    df_qc = qc_wbc_scatter(df_qc)\n\n                case 'rbc' | 'erythro':\n                    df_qc = qc_rbc(df_qc)\n\n                case 'plausible_range':\n                    df_qc = qc_plausible_range(df_qc)\n\n                case 'flags' | 'suspicious_flags':\n                    pass\n\n                case 'fail' | 'failure':\n                    pass\n\n                case 'standard_values':\n                    df_qc = qc_standard_values(df_qc)\n\n                case '_':\n                    print(f\"{qc} is not a valid QC. It will be skipped.\")\n\n            if verbose:\n                print(\"\\tDONE!\")\n\n        else:\n            print(f\"{qc} is not a valid QC. It will be skipped.\")\n\n    return df_qc\n</code></pre> <p><code>qc_wbc_scatter</code></p> <p>Perform quality control (QC) on the white blood cells (WBCs) scatter measurement parameters.</p> <p>Namely, it looks at the coefficient of variance (CV) of the following parameters:</p> <ul> <li><code>neutrophil_size_mean</code></li> <li><code>neutrophil_intracellular_complexity</code></li> <li><code>neutrophil_lobularity_polarized</code></li> <li><code>neutrophil_lobularity_depolarized</code></li> <li><code>neutrophil_dna_staining</code></li> <li><code>lymphocyte_size_mean</code></li> <li><code>lymphocyte_intracellular_complexity</code></li> </ul> <p>and if it is below <code>threshold</code> (which defaults to <code>1e-14</code>), it sets  both values (that of the parameter and its corresponding CV) to numpy's  <code>NaN</code>.</p> <p>Info</p> <p>This function was adapted from the original implementation in <code>quality.py</code> by Bram van Es.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>DataFrame with the clean data to be checked.</p> <p>Tip</p> <p>Cleaning can be done using the function clean_dataframe</p> required <code>threshold</code> <code>float</code> <p>When the CV of any parameter is below the threshold, both the parameter and its CV will be replaced by a <code>NaN</code>.</p> <code>1e-14</code> <code>machine</code> <code>str</code> <p>What machine does the data correspond to. Possible values are:</p> <ul> <li><code>sapphire</code> or <code>sapph</code> - Sapphire</li> <li><code>alinity</code> or <code>alin</code> - Alinity hq</li> </ul> <p>Info</p> <p>No functionality yet, but might be useful in the future.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Define if verbose output will be printed (<code>True</code>) or not (<code>False</code>).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>df_qc</code> <code>pandas DataFrame</code> <p>DataFrame with quality controlled data.</p> Source code in <code>pycelldyn/quality_control.py</code> <pre><code>def qc_wbc_scatter(df, threshold=1e-14, machine=None, verbose=True):\n    \"\"\" `qc_wbc_scatter`\n\n    Perform quality control (QC) on the white blood cells (WBCs) scatter\n    measurement parameters.\n\n    Namely, it looks at the coefficient of variance (CV) of the following\n    parameters:\n\n    * `neutrophil_size_mean`\n    * `neutrophil_intracellular_complexity`\n    * `neutrophil_lobularity_polarized`\n    * `neutrophil_lobularity_depolarized`\n    * `neutrophil_dna_staining`\n    * `lymphocyte_size_mean`\n    * `lymphocyte_intracellular_complexity`\n\n    and if it is below `threshold` (which defaults to `1e-14`), it sets \n    both values (that of the parameter and its corresponding CV) to numpy's \n    `NaN`.\n\n    !!! info\n        This function was adapted from the original implementation in\n        `quality.py` by Bram van Es.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        DataFrame with the clean data to be checked.\n\n        !!! tip\n            Cleaning can be done using the function clean_dataframe\n\n    threshold : float\n        When the CV of any parameter is below the threshold, both the\n        parameter and its CV will be replaced by a `NaN`.\n\n    machine : str\n        What machine does the data correspond to. Possible values are:\n\n        * `sapphire` or `sapph` - Sapphire\n        * `alinity` or `alin` - Alinity hq\n\n        !!! info\n            No functionality yet, but might be useful in the future.\n\n    verbose : bool\n        Define if verbose output will be printed (`True`) or not (`False`).\n\n    Returns\n    -------\n    df_qc : pandas DataFrame\n        DataFrame with quality controlled data.\n    \"\"\"\n\n    df_qc = df.copy()\n\n    # Get the relevant columns.\n    # These are the parameter names (not the CV names).\n    cols_wbc_scatter = misc.get_cols_wbc_scatter()\n\n    for col in cols_wbc_scatter:\n\n        # Create the CV parameter name by just appending `_cv` at the end.\n        col_cv = col + '_cv'\n\n        # Perform QC only when both the parameter and its corresponding CV\n        # column are present in the DataFrame.\n        if (col in df_qc.columns) and (col_cv in df_qc.columns):\n            df_qc.loc[df[col_cv] &lt; threshold, [col_cv, col]] = np.nan\n\n            if verbose:\n                print(f\"\\tQC for WBC scatter parameters performed on {col} and {col_cv}.\")\n\n        # Otherwise, do nothing.\n        else:\n            if verbose:\n                print(f\"\\tColumn {col} and/or {col_cv} not present in DataFrame. No WBC scatter QC performed.\")\n\n    return df_qc\n</code></pre> <p><code>qc_rbc</code></p> <p>Perform quality control (QC) on (some) red blood cells (RBCs) parameters.</p> <p>Namely, it looks at the following parameters and if they are below  (i.e., <code>&lt;</code>), their corresponding threshold, they will be replaced by  numpy's <code>NaN</code>.</p> <p>TODO: c_mode_rtc (mode_reti) - why change to NaN when 0?</p> Parameter Threshold Additional comments <code>reticulocytes</code> <code>1e-4</code> <code>reticulocytes_perc</code> <code>1e-4</code> <code>irf</code> <code>1e-4</code> Immature reticulocyte fraction <code>rbc_intracellular_complexity</code> <code>1e-4</code> <code>rbc_intracellular_complexity_cv</code> <code>1e-4</code> <code>rbc_population_position</code> <code>1e-4</code> <code>rbc_population_position_cv</code> <code>1e-4</code> <code>reticulocyte_population_position</code> <code>1e-4</code> <code>reticulocyte_population_position_cv</code> <code>1e-4</code> <code>mchcr</code> <code>1e-4</code> Mean Corpuscular HGB Concentration per Reticulocyte <code>mchr_nl</code> <code>1e-4</code> Mean corpuscular hemoglobin per reticulocyte, aka reticulocyte hemoglobin content (in NL units) <code>mcvr</code> <code>1e-4</code> Mean corpuscular volume (aka mean cell volume) of reticulocytes <code>hdw</code> <code>1e-4</code> Hemoglobin distribution width per RBC <code>rbc_hypochromic_perc</code> <code>1e-30</code> Hypochromic RBCs (RBCs with hemoglobin &lt; 28 g/dL) percentage <code>rbc_hyperchromic_perc</code> <code>1e-30</code> Hyperchromic RBC (RBCs with hemoglobin &gt; 41 g/dL) percentage <p>Info</p> <p>This function was adapted from the original implementation in <code>quality.py</code> by Bram van Es.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>DataFrame with the clean data to be checked.</p> <p>Tip</p> <p>Cleaning can be done using the function clean_dataframe</p> required <code>machine</code> <code>str</code> <p>What machine does the data correspond to. Possible values are:</p> <ul> <li><code>sapphire</code> or <code>sapph</code> - Sapphire</li> <li><code>alinity</code> or <code>alin</code> - Alinity hq</li> </ul> <p>Info</p> <p>No functionality yet, but might be useful in the future.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Define if verbose output will be printed (<code>True</code>) or not (<code>False</code>).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>df_qc</code> <code>pandas DataFrame</code> <p>DataFrame with quality controlled data.</p> Source code in <code>pycelldyn/quality_control.py</code> <pre><code>def qc_rbc(df, machine=None, verbose=True):\n    \"\"\" `qc_rbc`\n\n    Perform quality control (QC) on (some) red blood cells (RBCs) parameters.\n\n    Namely, it looks at the following parameters and if they are below \n    (i.e., `&lt;`), their corresponding threshold, they will be replaced by \n    numpy's `NaN`.\n\n    TODO: c_mode_rtc (mode_reti) - why change to NaN when 0?\n\n    | Parameter                             | Threshold | Additional comments                                               |\n    |---------------------------------------|-----------|-------------------------------------------------------------------|\n    | `reticulocytes`                       | `1e-4`    |                                                                   |\n    | `reticulocytes_perc`                  | `1e-4`    |                                                                   |\n    | `irf`                                 | `1e-4`    | Immature reticulocyte fraction                                    |\n    | `rbc_intracellular_complexity`        | `1e-4`    |                                                                   |\n    | `rbc_intracellular_complexity_cv`     | `1e-4`    |                                                                   |\n    | `rbc_population_position`             | `1e-4`    |                                                                   |\n    | `rbc_population_position_cv`          | `1e-4`    |                                                                   |\n    | `reticulocyte_population_position`    | `1e-4`    |                                                                   |\n    | `reticulocyte_population_position_cv` | `1e-4`    |                                                                   |\n    | `mchcr`                               | `1e-4`    | Mean Corpuscular HGB Concentration per Reticulocyte               |\n    | `mchr_nl`                             | `1e-4`    | Mean corpuscular hemoglobin per reticulocyte, aka reticulocyte hemoglobin content (in NL units)|\n    | `mcvr`                                | `1e-4`    | Mean corpuscular volume (aka mean cell volume) of reticulocytes   |\n    | `hdw`                                 | `1e-4`    | Hemoglobin distribution width per RBC                             |\n    | `rbc_hypochromic_perc`                | `1e-30`   | Hypochromic RBCs (RBCs with hemoglobin &lt; 28 g/dL) percentage      |\n    | `rbc_hyperchromic_perc`               | `1e-30`   | Hyperchromic RBC (RBCs with hemoglobin &gt; 41 g/dL) percentage      |\n\n    !!! info\n        This function was adapted from the original implementation in\n        `quality.py` by Bram van Es.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        DataFrame with the clean data to be checked.\n\n        !!! tip\n            Cleaning can be done using the function clean_dataframe\n\n    machine : str\n        What machine does the data correspond to. Possible values are:\n\n        * `sapphire` or `sapph` - Sapphire\n        * `alinity` or `alin` - Alinity hq\n\n        !!! info\n            No functionality yet, but might be useful in the future.\n\n    verbose : bool\n        Define if verbose output will be printed (`True`) or not (`False`).\n\n    Returns\n    -------\n    df_qc : pandas DataFrame\n        DataFrame with quality controlled data.\n    \"\"\"\n\n    df_qc = df.copy()\n\n    # Relevant columns.\n    cols_rbc = ['reticulocytes',\n                'reticulocytes_perc',\n                'irf',\n                'rbc_intracellular_complexity',\n                'rbc_intracellular_complexity_cv',\n                'rbc_population_position',\n                'rbc_population_position_cv',\n                'reticulocyte_population_position',\n                'reticulocyte_population_position_cv',\n                'mchcr',\n                'mchr_nl',\n                'mcvr',\n                'hdw',\n                'rbc_hypochromic_perc',\n                'rbc_hyperchromic_perc'\n                ]\n\n    for col in cols_rbc:\n\n        # Perform QC only when the correpsonding column is present \n        # in the DataFrame.\n        if col in df_qc.columns:\n\n            # Define threshold. \n            if col in ['rbc_hypochromic_perc', 'rbc_hyperchromic_perc']:\n                threshold = 1e-30\n            else:\n                threshold = 1e-4\n            df_qc.loc[df[col] &lt; threshold, col] = np.nan\n\n            if verbose:\n                print(f\"\\tQC for RBCs performed on {col}.\")\n\n        # Otherwise, do nothing.\n        else:\n            if verbose:\n                print(f\"\\tColumn {col} not present in DataFrame. No RBC QC performed.\")\n\n    return df_qc\n</code></pre> <p><code>qc_standard_values</code></p> <p>Perform quality control (QC) by removing rows that do not have  a predefined standard value.</p> <p>Namely, it looks at the following parameters and their corresponding (standard) values:</p> <p>TODO: What is this for? Why remove rows? TODO: Why only these parameters? TODO: Why hemoglobin in NL units?</p> Parameter Value Additional comments <code>rbc_intracellular_complexity</code> <code>182</code> <code>rbc_population_position</code> <code>85</code> <code>neutrophil_size_mean</code> <code>140</code> <code>neutrophil_intracellular_complexity</code> <code>150</code> <code>neutrophil_lobularity_polarized</code> <code>125</code> <code>neutrophil_lobularity_depolarized</code> <code>28</code> <code>neutrophil_dna_staining</code> <code>69</code> <code>lymphocyte_size_mean</code> <code>100</code> <code>lymphocyte_intracellular_complexity</code> <code>75</code> <code>hb_nl</code> <code>6.206e-21</code> Hemoglobin (in NL units) <code>mch_usa</code> <code>0.6206</code> Mean corpuscular hemoglobin (in USA units) <code>mchc_usa</code> <code>0.6206</code> Mean corpuscular hemoglobin concentration (in USA units) <code>rbc_intracellular_complexity_cv</code> <code>1.59341</code> <code>rbc_population_position_cv</code> <code>7.2</code> <p>Info</p> <p>This function was adapted from the original implementation in <code>quality.py</code> by Bram van Es.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>DataFrame with the clean data to be checked.</p> <p>Tip</p> <p>Cleaning can be done using the function clean_dataframe</p> required <code>machine</code> <code>str</code> <p>What machine does the data correspond to. Possible values are:</p> <ul> <li><code>sapphire</code> or <code>sapph</code> - Sapphire</li> <li><code>alinity</code> or <code>alin</code> - Alinity hq</li> </ul> <p>Info</p> <p>No functionality yet, but might be useful in the future.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Define if verbose output will be printed (<code>True</code>) or not (<code>False</code>).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>df_qc</code> <code>pandas DataFrame</code> <p>DataFrame with quality controlled data.</p> Source code in <code>pycelldyn/quality_control.py</code> <pre><code>def qc_standard_values(df, machine=None, verbose=True):\n    \"\"\" `qc_standard_values`\n\n    Perform quality control (QC) by removing rows that do *not* have \n    a predefined standard value.\n\n    Namely, it looks at the following parameters and their corresponding\n    (standard) values:\n\n    TODO: What is this for? Why remove rows?\n    TODO: Why only these parameters?\n    TODO: Why hemoglobin in NL units?\n\n    | Parameter                             | Value       | Additional comments |\n    |---------------------------------------|-------------|---------------------|\n    | `rbc_intracellular_complexity`        | `182`       | |\n    | `rbc_population_position`             | `85`        | |\n    | `neutrophil_size_mean`                | `140`       | |\n    | `neutrophil_intracellular_complexity` | `150`       | |\n    | `neutrophil_lobularity_polarized`     | `125`       | |\n    | `neutrophil_lobularity_depolarized`   | `28`        | |\n    | `neutrophil_dna_staining`             | `69`        | |\n    | `lymphocyte_size_mean`                | `100`       | |\n    | `lymphocyte_intracellular_complexity` | `75`        | |\n    | `hb_nl`                               | `6.206e-21` | Hemoglobin (in NL units) |\n    | `mch_usa`                             | `0.6206`    | Mean corpuscular hemoglobin (in USA units) |\n    | `mchc_usa`                            | `0.6206`    | Mean corpuscular hemoglobin concentration (in USA units) |\n    | `rbc_intracellular_complexity_cv`     | `1.59341`   | |\n    | `rbc_population_position_cv`          | `7.2`       | |\n\n    !!! info\n        This function was adapted from the original implementation in\n        `quality.py` by Bram van Es.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        DataFrame with the clean data to be checked.\n\n        !!! tip\n            Cleaning can be done using the function clean_dataframe\n\n    machine : str\n        What machine does the data correspond to. Possible values are:\n\n        * `sapphire` or `sapph` - Sapphire\n        * `alinity` or `alin` - Alinity hq\n\n        !!! info\n            No functionality yet, but might be useful in the future.\n\n    verbose : bool\n        Define if verbose output will be printed (`True`) or not (`False`).\n\n    Returns\n    -------\n    df_qc : pandas DataFrame\n        DataFrame with quality controlled data.\n    \"\"\"\n\n    df_qc = df.copy()\n\n    # Pair of relevant columns and standard values.\n    cols_standard_values = {'rbc_intracellular_complexity': 182,\n                            'rbc_population_position': 85,\n                            'neutrophil_size_mean': 140,\n                            'neutrophil_intracellular_complexity': 150,\n                            'neutrophil_lobularity_polarized': 125,\n                            'neutrophil_lobularity_depolarized': 28,\n                            'neutrophil_dna_staining': 69,\n                            'lymphocyte_size_mean': 100,\n                            'lymphocyte_intracellular_complexity': 75,\n                            'hb_nl': 6.206e-21,\n                            'mch_usa': 0.6206,\n                            'mchc_usa': 0.6206,\n                            'rbc_intracellular_complexity_cv': 1.59341,\n                            'rbc_population_position_cv': 7.2,\n                            }\n\n    for col, value in cols_standard_values:\n\n        # Perform QC only when the corresponding column is present \n        # in the DataFrame.\n        if col in df_qc.columns:\n\n            # Remove rows that do not have the corresponding value.\n            df_qc = df.loc[lambda x: x[col] != value]\n\n            if verbose:\n                print(f\"\\tQC for standard values performed on {col}.\")\n\n        # Otherwise, do nothing.\n        else:\n            if verbose:\n                print(f\"\\tColumn {col} not present in DataFrame. No standard value QC performed.\")\n\n    return df_qc\n</code></pre> <p><code>qc_plausible_range</code></p> <p>Perform quality control (QC) by converting values that are below or above an given threshold (defined in the data dictionary).</p> <p>TODO: Why convert to NaN and not clip?</p> <p>Info</p> <p>This function was adapted from the original implementation in <code>quality.py</code> by Bram van Es.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas DataFrame</code> <p>DataFrame with the clean data to be checked.</p> <p>Tip</p> <p>Cleaning can be done using the function clean_dataframe</p> required <code>df_data_dictionary</code> <code>pandas DataFrame</code> <p>DataFrame with data dictionary information. It should have at least the following columns:</p> <ul> <li><code>Computer name</code> - The computer name of each parameter.</li> <li><code>Min</code> - Minimal allowed value</li> <li><code>Max</code> - Maximum allowed value</li> </ul> <p>Tip</p> <p>If the parameter has no min or max values, these should be filled in as a single dash (<code>-</code>).</p> required <code>machine</code> <code>str</code> <p>What machine does the data correspond to. Possible values are:</p> <ul> <li><code>sapphire</code> or <code>sapph</code> - Sapphire</li> <li><code>alinity</code> or <code>alin</code> - Alinity hq</li> </ul> <p>Info</p> <p>No functionality yet, but might be useful in the future.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Define if verbose output will be printed (<code>True</code>) or not (<code>False</code>).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>df_qc</code> <code>pandas DataFrame</code> <p>DataFrame with quality controlled data.</p> Source code in <code>pycelldyn/quality_control.py</code> <pre><code>def qc_plausible_range(df, df_data_dictionary, machine=None, verbose=True):\n    \"\"\" `qc_plausible_range`\n\n    Perform quality control (QC) by converting values that are below\n    or above an given threshold (defined in the data dictionary).\n\n    TODO: Why convert to NaN and not clip?\n\n    !!! info\n        This function was adapted from the original implementation in\n        `quality.py` by Bram van Es.\n\n    Parameters\n    ----------\n    df : pandas DataFrame\n        DataFrame with the clean data to be checked.\n\n        !!! tip\n            Cleaning can be done using the function clean_dataframe\n\n    df_data_dictionary : pandas DataFrame\n        DataFrame with data dictionary information. It should have\n        at least the following columns:\n\n        * `Computer name` - The computer name of each parameter.\n        * `Min` - Minimal allowed value\n        * `Max` - Maximum allowed value\n\n        !!! tip\n            If the parameter has no min or max values, these should be\n            filled in as a single dash (`-`).\n\n    machine : str\n        What machine does the data correspond to. Possible values are:\n\n        * `sapphire` or `sapph` - Sapphire\n        * `alinity` or `alin` - Alinity hq\n\n        !!! info\n            No functionality yet, but might be useful in the future.\n\n    verbose : bool\n        Define if verbose output will be printed (`True`) or not (`False`).\n\n    Returns\n    -------\n    df_qc : pandas DataFrame\n        DataFrame with quality controlled data.\n    \"\"\"\n\n    df_qc = df.copy()\n\n    # Check that columns of interest are present in the data dictionary.\n    cols_interest = ['Computer name', 'Min', 'Max']\n    for col in cols_interest:\n        if col not in df_data_dictionary.columns:\n            raise Exception(f\"Column '{col}' not present in df_data_dictionary\")\n\n    # Select the data dictionary's columns of interest.\n    df_data_dictionary = df_data_dictionary[cols_interest]\n    df_data_dictionary = df_data_dictionary.set_index('Computer name')\n\n    # Make sure that Min and Max columns are cast to floats properly.\n    # `-` are replaced to `np.nan`.\n    for col in ['Min', 'Max']:\n        df_data_dictionary[col] = df_data_dictionary[col].replace('-', np.nan)\n        df_data_dictionary[col] = df_data_dictionary[col].astype(float).fillna(np.nan)\n\n\n    # Try to perform QC on all data columns.\n    for col in df_qc.columns:\n\n        # Check that data column exists in the data dictionary.\n        if col in df_data_dictionary.index:\n\n            col_min = df_data_dictionary.loc[col, 'Min']\n            col_max = df_data_dictionary.loc[col, 'Max']\n\n            # Perform QC only when an existing min limit is found.\n            if col_min == col_min:\n                df_qc.loc[df_qc[col] &lt; col_min, col] = np.nan\n                if verbose:\n                    print(f\"\\tQC for plausible range (min = {col_min}) performed on {col}.\")\n            else:\n                print(f\"\\tQC for plausible range (min) NOT performed on {col} due to NaN min value.\")\n\n            # Perform QC only when an existing max limit is found.\n            if col_max == col_max:\n                df_qc.loc[df_qc[col] &gt; col_max, col] = np.nan\n                if verbose:\n                    print(f\"\\tQC for plausible range (max = {col_max}) performed on {col}.\")\n            else:\n                print(f\"\\tQC for plausible range (max) NOT performed on {col} due to NaN max value.\")\n\n        # If the column does not exist, do nothing.\n        else:\n            if verbose:\n                print(f\"\\tColumn {col} not present df_data_dictionary. No plausible range QC performed.\")\n\n    return df_qc\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>We have created a few Jupyter notebooks where we showcase the use of <code>PyCellDyn</code>. </p> <p>TODO</p>"}]}