{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffc0dad",
   "metadata": {},
   "source": [
    "\n",
    "<h1><img align=\"right\" width=\"20%\" src=\"../multimedia/kite_logo.png\"> CXLP </h1>\n",
    "\n",
    "# 01 - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b1b3b",
   "metadata": {},
   "source": [
    "## Objective\n",
    "This notebook shows basic functionality of the `CXLP` package.\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423e031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "import cxlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a24d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution of this notebook started on 2023-10-17 16:52:46.590399\n"
     ]
    }
   ],
   "source": [
    "current_timestamp = pd.Timestamp.now()\n",
    "print(f\"Execution of this notebook started on {current_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7b2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = pathlib.Path('.', 'data')\n",
    "path_results = pathlib.Path('.', 'results')\n",
    "\n",
    "# Make sure paths exist.\n",
    "for path_ in [path_data, path_results]:    \n",
    "    if not path_.exists():\n",
    "        print(f\"Directory {path_} does not exist. Creating...\", flush=False, end='')\n",
    "        path_.mkdir(parents=True)\n",
    "        print(\"\\tDONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e555ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = 'clp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e7756",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Read data\n",
    "Make sure to replace `path_to_updated_file` with your proper path\n",
    "(i.e., replace `my_user_name` with your actual user.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0406811",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_updated_file = pathlib.Path(r'C:\\Users\\my_user_name\\Gilead Sciences\\TCF04 MSAT Data Science - Process Files')\n",
    "path_to_updated_file = pathlib.Path(r'C:\\Users\\amoncadatorres\\Gilead Sciences\\TCF04 MSAT Data Science - Process Files')\n",
    "\n",
    "# path_new_file = cxlp.copy_most_recent_data_file(product, 'working', path_to_updated_file, path_data)\n",
    "path_new_file = './data/2023-08-25 CLP Working Data.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350ff637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading YESCARTA file 2023-08-25 CLP Working Data.xlsx... \tDONE!\n"
     ]
    }
   ],
   "source": [
    "df = cxlp.read_excel_file_raw(path_new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec55cc66",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Pre-processing\n",
    "Pre-processing steps can be done individually...\n",
    "\n",
    "> Remember that renaming columns should always be the first \n",
    "> pre-processing step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac623b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming columns...\tDONE!\n",
      "Cleaning columns...\n",
      "+ Cleaning categorical column batch_id...\t DONE!\n",
      "+ Cleaning categorical column cell_order...\t DONE!\n",
      "+ Cleaning categorical column subject_id...\t DONE!\n",
      "+ Cleaning categorical column apheresis_site...\t DONE!\n",
      "+ Cleaning categorical column apheresis_country...\t DONE!\n",
      "+ Cleaning categorical column suite...\t DONE!\n",
      "+ Cleaning categorical column facility_intermediate...\t DONE!\n",
      "+ Cleaning categorical column facility_final_product...\t DONE!\n",
      "+ Cleaning categorical column item_number...\t DONE!\n",
      "+ Cleaning categorical column indication...\t DONE!\n",
      "+ Cleaning categorical column line_therapy...\t DONE!\n",
      "+ Cleaning categorical column run_type...\t DONE!\n",
      "+ Cleaning categorical column apheresis_type...\t DONE!\n",
      "+ Cleaning categorical column process_type...\t DONE!\n",
      "+ Cleaning categorical column cell_order_reclassified_frozen...\t DONE!\n",
      "- Column start_day0_date will not be cleaned and left as is.\n",
      "- Column harvest_date will not be cleaned and left as is.\n",
      "- Column termination_date will not be cleaned and left as is.\n",
      "- Column harvest_termination_date will not be cleaned and left as is.\n",
      "- Column apheresis_spiked_welded_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column apheresis_starting_volume_unadjusted...\t DONE!\n",
      "+ Cleaning numerical column apheresis_volume_adjusted...\t DONE!\n",
      "+ Cleaning numerical column apheresis_volume_needed...\t DONE!\n",
      "+ Cleaning numerical column pericell_volume...\t DONE!\n",
      "+ Cleaning numerical column neatcell_volume_initial...\t DONE!\n",
      "+ Cleaning numerical column neatcell_viability...\t DONE!\n",
      "+ Cleaning numerical column neatcell_recovery...\t DONE!\n",
      "- Column pbmc_thaw_wash_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column pbmc_thaw_wash_viability...\t DONE!\n",
      "+ Cleaning numerical column tcell_activation_density...\t DONE!\n",
      "+ Cleaning numerical column viability_wash1...\t DONE!\n",
      "+ Cleaning numerical column transduction_postseeding_density...\t DONE!\n",
      "- Column transduction_duration will not be cleaned and left as is.\n",
      "+ Cleaning numerical column transduction_duration_h...\t DONE!\n",
      "+ Cleaning numerical column viability_wash2...\t DONE!\n",
      "+ Cleaning numerical column bag_volume_total_expansion...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day3...\t DONE!\n",
      "+ Cleaning numerical column expansion_viability_day3...\t DONE!\n",
      "+ Cleaning numerical column culture_volume_day5...\t DONE!\n",
      "+ Cleaning numerical column viability_day5...\t DONE!\n",
      "+ Cleaning numerical column transduction_day5...\t DONE!\n",
      "+ Cleaning numerical column culture_volume_day6...\t DONE!\n",
      "+ Cleaning numerical column viability_day6...\t DONE!\n",
      "+ Cleaning numerical column transduction_day6...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day7...\t DONE!\n",
      "+ Cleaning numerical column viability_day7...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day8...\t DONE!\n",
      "+ Cleaning numerical column viability_day8...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day9...\t DONE!\n",
      "+ Cleaning numerical column viability_day9...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day10...\t DONE!\n",
      "+ Cleaning numerical column viability_day10...\t DONE!\n",
      "- Column harvest_wash_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column fold_expansion_per_day...\t DONE!\n",
      "+ Cleaning numerical column viability_harvest...\t DONE!\n",
      "+ Cleaning numerical column transduction_harvest...\t DONE!\n",
      "+ Cleaning numerical column patient_weight...\t DONE!\n",
      "+ Cleaning numerical column car_cells_total_final_product...\t DONE!\n",
      "+ Cleaning numerical column recovery_wash3...\t DONE!\n",
      "- Column time_harvest_cs10 will not be cleaned and left as is.\n",
      "+ Cleaning numerical column time_harvest_cs10_h...\t DONE!\n",
      "+ Cleaning numerical column time_cs10_crf...\t DONE!\n",
      "+ Cleaning numerical column time_crf_cryopod...\t DONE!\n",
      "+ Cleaning numerical column time_ln2_shipper...\t DONE!\n",
      "+ Cleaning categorical column status...\t DONE!\n",
      "+ Cleaning categorical column lot_released...\t DONE!\n",
      "+ Cleaning numerical column dose_patient...\t DONE!\n",
      "+ Cleaning categorical column dose_patient_unit...\t DONE!\n",
      "+ Cleaning numerical column ifng...\t DONE!\n",
      "+ Cleaning categorical column specification_number...\t DONE!\n",
      "+ Cleaning numerical column cd3_cells_p...\t DONE!\n",
      "+ Cleaning categorical column bsa...\t DONE!\n",
      "+ Cleaning numerical column gentamicin...\t DONE!\n",
      "+ Cleaning categorical column rcr_qpcr...\t DONE!\n",
      "+ Cleaning categorical column rcl_qpcr...\t DONE!\n",
      "+ Cleaning categorical column mycoplasma...\t DONE!\n",
      "+ Cleaning categorical column gram_stain...\t DONE!\n",
      "+ Cleaning numerical column vcn_bag1...\t DONE!\n",
      "+ Cleaning numerical column vcn_bag2...\t DONE!\n",
      "+ Cleaning categorical column vcn_unit...\t DONE!\n",
      "+ Cleaning categorical column vi_bag1...\t DONE!\n",
      "+ Cleaning categorical column vi_bag2...\t DONE!\n",
      "+ Cleaning categorical column identity_bag1...\t DONE!\n",
      "+ Cleaning categorical column identity_bag2...\t DONE!\n",
      "+ Cleaning categorical column endotoxin_bag1...\t DONE!\n",
      "+ Cleaning categorical column endotoxin_bag2...\t DONE!\n",
      "+ Cleaning categorical column sterility_bag1...\t DONE!\n",
      "+ Cleaning categorical column sterility_bag2...\t DONE!\n",
      "- Column coa_interim_signature_date will not be cleaned and left as is.\n",
      "+ Cleaning numerical column number_bags...\t DONE!\n",
      "- Column lonza_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column ifng_per_car...\t DONE!\n",
      "+ Cleaning categorical column termination_reason...\t DONE!\n",
      "+ Cleaning categorical column comments...\t DONE!\n",
      "+ Cleaning categorical column lims_recorded_by...\t DONE!\n",
      "- Column lims_record_date will not be cleaned and left as is.\n",
      "+ Cleaning categorical column lims_verified_by...\t DONE!\n",
      "- Column lims_verification_date will not be cleaned and left as is.\n",
      "+ Cleaning categorical column recorded_by...\t DONE!\n",
      "- Column record_date will not be cleaned and left as is.\n",
      "+ Cleaning categorical column verified_by...\t DONE!\n",
      "- Column verification_date will not be cleaned and left as is.\n",
      "\tDONE!\n"
     ]
    }
   ],
   "source": [
    "path_dictionary = '../dictionaries/CLP Data Dictionary v2.3.xlsx'\n",
    "df_renamed = cxlp.rename_columns(df, product, path_dictionary)\n",
    "df_preprocessed = cxlp.clean_dataframe(df_renamed, product, path_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4f6b7",
   "metadata": {},
   "source": [
    "...or all of them together in a single line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2e72de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming columns...\tDONE!\n",
      "Cleaning columns...\n",
      "+ Cleaning categorical column batch_id...\t DONE!\n",
      "+ Cleaning categorical column cell_order...\t DONE!\n",
      "+ Cleaning categorical column subject_id...\t DONE!\n",
      "+ Cleaning categorical column apheresis_site...\t DONE!\n",
      "+ Cleaning categorical column apheresis_country...\t DONE!\n",
      "+ Cleaning categorical column suite...\t DONE!\n",
      "+ Cleaning categorical column facility_intermediate...\t DONE!\n",
      "+ Cleaning categorical column facility_final_product...\t DONE!\n",
      "+ Cleaning categorical column item_number...\t DONE!\n",
      "+ Cleaning categorical column indication...\t DONE!\n",
      "+ Cleaning categorical column line_therapy...\t DONE!\n",
      "+ Cleaning categorical column run_type...\t DONE!\n",
      "+ Cleaning categorical column apheresis_type...\t DONE!\n",
      "+ Cleaning categorical column process_type...\t DONE!\n",
      "+ Cleaning categorical column cell_order_reclassified_frozen...\t DONE!\n",
      "- Column start_day0_date will not be cleaned and left as is.\n",
      "- Column harvest_date will not be cleaned and left as is.\n",
      "- Column termination_date will not be cleaned and left as is.\n",
      "- Column harvest_termination_date will not be cleaned and left as is.\n",
      "- Column apheresis_spiked_welded_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column apheresis_starting_volume_unadjusted...\t DONE!\n",
      "+ Cleaning numerical column apheresis_volume_adjusted...\t DONE!\n",
      "+ Cleaning numerical column apheresis_volume_needed...\t DONE!\n",
      "+ Cleaning numerical column pericell_volume...\t DONE!\n",
      "+ Cleaning numerical column neatcell_volume_initial...\t DONE!\n",
      "+ Cleaning numerical column neatcell_viability...\t DONE!\n",
      "+ Cleaning numerical column neatcell_recovery...\t DONE!\n",
      "- Column pbmc_thaw_wash_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column pbmc_thaw_wash_viability...\t DONE!\n",
      "+ Cleaning numerical column tcell_activation_density...\t DONE!\n",
      "+ Cleaning numerical column viability_wash1...\t DONE!\n",
      "+ Cleaning numerical column transduction_postseeding_density...\t DONE!\n",
      "- Column transduction_duration will not be cleaned and left as is.\n",
      "+ Cleaning numerical column transduction_duration_h...\t DONE!\n",
      "+ Cleaning numerical column viability_wash2...\t DONE!\n",
      "+ Cleaning numerical column bag_volume_total_expansion...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day3...\t DONE!\n",
      "+ Cleaning numerical column expansion_viability_day3...\t DONE!\n",
      "+ Cleaning numerical column culture_volume_day5...\t DONE!\n",
      "+ Cleaning numerical column viability_day5...\t DONE!\n",
      "+ Cleaning numerical column transduction_day5...\t DONE!\n",
      "+ Cleaning numerical column culture_volume_day6...\t DONE!\n",
      "+ Cleaning numerical column viability_day6...\t DONE!\n",
      "+ Cleaning numerical column transduction_day6...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day7...\t DONE!\n",
      "+ Cleaning numerical column viability_day7...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day8...\t DONE!\n",
      "+ Cleaning numerical column viability_day8...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day9...\t DONE!\n",
      "+ Cleaning numerical column viability_day9...\t DONE!\n",
      "+ Cleaning numerical column volume_adjusted_day10...\t DONE!\n",
      "+ Cleaning numerical column viability_day10...\t DONE!\n",
      "- Column harvest_wash_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column fold_expansion_per_day...\t DONE!\n",
      "+ Cleaning numerical column viability_harvest...\t DONE!\n",
      "+ Cleaning numerical column transduction_harvest...\t DONE!\n",
      "+ Cleaning numerical column patient_weight...\t DONE!\n",
      "+ Cleaning numerical column car_cells_total_final_product...\t DONE!\n",
      "+ Cleaning numerical column recovery_wash3...\t DONE!\n",
      "- Column time_harvest_cs10 will not be cleaned and left as is.\n",
      "+ Cleaning numerical column time_harvest_cs10_h...\t DONE!\n",
      "+ Cleaning numerical column time_cs10_crf...\t DONE!\n",
      "+ Cleaning numerical column time_crf_cryopod...\t DONE!\n",
      "+ Cleaning numerical column time_ln2_shipper...\t DONE!\n",
      "+ Cleaning categorical column status...\t DONE!\n",
      "+ Cleaning categorical column lot_released...\t DONE!\n",
      "+ Cleaning numerical column dose_patient...\t DONE!\n",
      "+ Cleaning categorical column dose_patient_unit...\t DONE!\n",
      "+ Cleaning numerical column ifng...\t DONE!\n",
      "+ Cleaning categorical column specification_number...\t DONE!\n",
      "+ Cleaning numerical column cd3_cells_p...\t DONE!\n",
      "+ Cleaning categorical column bsa...\t DONE!\n",
      "+ Cleaning numerical column gentamicin...\t DONE!\n",
      "+ Cleaning categorical column rcr_qpcr...\t DONE!\n",
      "+ Cleaning categorical column rcl_qpcr...\t DONE!\n",
      "+ Cleaning categorical column mycoplasma...\t DONE!\n",
      "+ Cleaning categorical column gram_stain...\t DONE!\n",
      "+ Cleaning numerical column vcn_bag1...\t DONE!\n",
      "+ Cleaning numerical column vcn_bag2...\t DONE!\n",
      "+ Cleaning categorical column vcn_unit...\t DONE!\n",
      "+ Cleaning categorical column vi_bag1...\t DONE!\n",
      "+ Cleaning categorical column vi_bag2...\t DONE!\n",
      "+ Cleaning categorical column identity_bag1...\t DONE!\n",
      "+ Cleaning categorical column identity_bag2...\t DONE!\n",
      "+ Cleaning categorical column endotoxin_bag1...\t DONE!\n",
      "+ Cleaning categorical column endotoxin_bag2...\t DONE!\n",
      "+ Cleaning categorical column sterility_bag1...\t DONE!\n",
      "+ Cleaning categorical column sterility_bag2...\t DONE!\n",
      "- Column coa_interim_signature_date will not be cleaned and left as is.\n",
      "+ Cleaning numerical column number_bags...\t DONE!\n",
      "- Column lonza_date_time will not be cleaned and left as is.\n",
      "+ Cleaning numerical column ifng_per_car...\t DONE!\n",
      "+ Cleaning categorical column termination_reason...\t DONE!\n",
      "+ Cleaning categorical column comments...\t DONE!\n",
      "+ Cleaning categorical column lims_recorded_by...\t DONE!\n",
      "- Column lims_record_date will not be cleaned and left as is.\n",
      "+ Cleaning categorical column lims_verified_by...\t DONE!\n",
      "- Column lims_verification_date will not be cleaned and left as is.\n",
      "+ Cleaning categorical column recorded_by...\t DONE!\n",
      "- Column record_date will not be cleaned and left as is.\n",
      "+ Cleaning categorical column verified_by...\t DONE!\n",
      "- Column verification_date will not be cleaned and left as is.\n",
      "\tDONE!\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed2 = cxlp.preprocess_raw_dataframe(df, product, path_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e9bfe",
   "metadata": {},
   "source": [
    "Notice how `df_preprocessed` and `df_preprocessed2` are the same.\n",
    "\n",
    "## Feature engineering\n",
    "There are certain columns that aren't part of the CLP/XLP data,\n",
    "but that they are quite useful. We add those columns to the DataFrame here.\n",
    "\n",
    "Similarly to pre-procesing, this can be done individually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4678bef1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns harvest_date and start_day0_date are present.\n",
      "Adding column `production_date`...\tDONE!\n",
      "Adding column `production_date_numeric`...\tDONE!\n",
      "Adding column `production_date_formatted`...\tDONE!\n",
      "Adding column `production_date_q_formatted`...\tDONE!\n",
      "Adding column `production_date_q`...\tDONE!\n",
      "Adding column `production_date_quarter`...\tDONE!\n",
      "Adding column `production_date_month`...\tDONE!\n",
      "Adding column `production_date_year`...\tDONE!\n",
      "Adding column `production_date_short`...\tDONE!\n",
      "Adding column `production_date_short_formatted`...\tDONE!\n",
      "Adding column `harvested`...\tDONE!\n",
      "Adding column `harvest_day`...\tDONE!\n",
      "Adding columns `attempt_number` and `attempt_type`...\tDONE!\n",
      "Adding column `verified`...\tDONE!\n",
      "Adding column `success`...\tDONE!\n"
     ]
    }
   ],
   "source": [
    "df_production_date = cxlp.add_production_date(df_preprocessed)\n",
    "df_production_dates = cxlp.add_production_date_columns(df_production_date)\n",
    "df_harvested = cxlp.add_harvested(df_production_dates)\n",
    "df_harvest_day = cxlp.add_harvest_day(df_harvested)\n",
    "df_attempts = cxlp.add_attempt_number_type(df_harvest_day) \n",
    "df_verified = cxlp.add_verified(df_attempts)\n",
    "df_engineered = cxlp.add_success(df_verified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fabe3c",
   "metadata": {},
   "source": [
    "...or all of them at once. Notice that for this to work, you should use\n",
    "the column names defined in `rename_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e02fae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns harvest_date and start_day0_date are present.\n",
      "Adding column `production_date`...\tDONE!\n",
      "Adding column `production_date_numeric`...\tDONE!\n",
      "Adding column `production_date_formatted`...\tDONE!\n",
      "Adding column `production_date_q_formatted`...\tDONE!\n",
      "Adding column `production_date_q`...\tDONE!\n",
      "Adding column `production_date_quarter`...\tDONE!\n",
      "Adding column `production_date_month`...\tDONE!\n",
      "Adding column `production_date_year`...\tDONE!\n",
      "Adding column `production_date_short`...\tDONE!\n",
      "Adding column `production_date_short_formatted`...\tDONE!\n",
      "Adding column `harvested`...\tDONE!\n",
      "Adding column `harvest_day`...\tDONE!\n",
      "Adding columns `attempt_number` and `attempt_type`...\tDONE!\n",
      "Adding column `verified`...\tDONE!\n",
      "Adding column `success`...\tDONE!\n"
     ]
    }
   ],
   "source": [
    "df_engineered2 = cxlp.add_engineered_columns(df_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574090b",
   "metadata": {},
   "source": [
    "Once again, notice how `df_engineered` and `df_engineered2` are the same.\n",
    "## Filtering\n",
    "We can do filtering very easily using [`pandas.DataFrame.query`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html)\n",
    "\n",
    "Every time we use `.query`, it is good practice to add `.copy()` at\n",
    "the end to make sure that a copy is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f338e61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tcf03']\n"
     ]
    }
   ],
   "source": [
    "df_tcf03 = df_engineered.query('facility_final_product == \"tcf03\"').copy()\n",
    "\n",
    "print(df_tcf03['facility_final_product'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3bfd44",
   "metadata": {},
   "source": [
    "We can also query using a variable by adding `@` in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7666760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tcf04']\n"
     ]
    }
   ],
   "source": [
    "site_interest = 'tcf04'\n",
    "df_tcf04 = df_engineered.query('facility_final_product == @site_interest').copy()\n",
    "\n",
    "print(df_tcf04['facility_final_product'].unique())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
